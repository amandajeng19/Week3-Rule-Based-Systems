{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZJV0yFyd4E4"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAT-ComputationalCreativity-Spring2025/Week3-Rule-Based-Systems/blob/main/markov_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngZK9TEWd4E7"
      },
      "source": [
        "# Markov Models Text Generation\n",
        "\n",
        "This notebook introduces Markov chains for text generation. We'll build a simple\n",
        "text generator that learns patterns from input text and generates new text with\n",
        "similar statistical properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ChZI8Z5Od4E7"
      },
      "outputs": [],
      "source": [
        "# First, let's import our required libraries\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBng2Pivd4E8"
      },
      "source": [
        "## Building the Markov Chain\n",
        "\n",
        "A Markov chain represents sequences of states where the probability of each state\n",
        "depends only on the previous state(s). In our case, each state will be a sequence\n",
        "of words, and we'll predict the next word based on this sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ytnRUYF_d4E8"
      },
      "outputs": [],
      "source": [
        "def build_markov_chain(text, order=2):\n",
        "    \"\"\"\n",
        "    Build a Markov chain from input text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to learn from\n",
        "        order (int): Number of words to use as state (context)\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping from state tuples to lists of possible next words\n",
        "    \"\"\"\n",
        "    chain = defaultdict(list)\n",
        "    words = text.split()\n",
        "\n",
        "    for i in range(len(words) - order):\n",
        "        # Create state tuple from current words\n",
        "        state = tuple(words[i:i+order])\n",
        "        # Get the next word\n",
        "        next_word = words[i+order]\n",
        "        # Add to chain\n",
        "        chain[state].append(next_word)\n",
        "\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k13VrjxPd4E9"
      },
      "source": [
        "## Generating Text\n",
        "\n",
        "Now we'll use our Markov chain to generate new text. We'll randomly select from\n",
        "the possible next words at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gPS3URBgd4E9"
      },
      "outputs": [],
      "source": [
        "def generate_text(chain, order=2, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate new text using the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain mapping states to possible next words\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    # Start with a random state from the chain\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            next_word = random.choice(chain[state])\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STaWdCvEd4E9"
      },
      "source": [
        "## Part 3: Basic Example\n",
        "\n",
        "Let's try our text generator with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDYJhiFBd4E9",
        "outputId": "efd58b70-3d41-4755-c88b-3d51ee8381a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick -> ['brown']\n",
            "quick brown -> ['fox', 'dog', 'dog']\n",
            "brown fox -> ['jumps']\n",
            "fox jumps -> ['over']\n",
            "jumps over -> ['the', 'the']\n",
            "over the -> ['lazy', 'lazy']\n",
            "the lazy -> ['dog.', 'fox.']\n",
            "lazy dog. -> ['A']\n",
            "dog. A -> ['quick']\n",
            "A quick -> ['brown']\n",
            "brown dog -> ['jumps', 'watches.']\n",
            "dog jumps -> ['over']\n",
            "lazy fox. -> ['The']\n",
            "fox. The -> ['lazy']\n",
            "The lazy -> ['fox']\n",
            "lazy fox -> ['sleeps']\n",
            "fox sleeps -> ['while']\n",
            "sleeps while -> ['the']\n",
            "while the -> ['quick']\n",
            "the quick -> ['brown']\n"
          ]
        }
      ],
      "source": [
        "# Sample text\n",
        "sample_text = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog.\n",
        "A quick brown dog jumps over the lazy fox.\n",
        "The lazy fox sleeps while the quick brown dog watches.\n",
        "\"\"\"\n",
        "\n",
        "# Build the chain\n",
        "chain = build_markov_chain(sample_text)\n",
        "\n",
        "# Examine the chain\n",
        "for state, words in chain.items():\n",
        "    print(f\"{' '.join(state)} -> {words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovAqUno7d4E9",
        "outputId": "44fbd817-0eaf-492f-da5d-1afb14072971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "fox jumps over the lazy dog. A quick brown dog jumps over the lazy dog. A quick brown dog watches.\n"
          ]
        }
      ],
      "source": [
        "# Generate some text\n",
        "print(\"Generated text:\")\n",
        "print(generate_text(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky7lMIhyd4E-"
      },
      "source": [
        "## Student Tasks\n",
        "\n",
        "1. Basic Implementation:\n",
        "   - Try changing the order parameter in build_markov_chain\n",
        "   - What happens with order=1 vs order=3?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbyuiW0jd4E-",
        "outputId": "c6a854c8-a379-450d-ac9a-e444fb43ba89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "The lazy dog. A quick brown fox jumps over the lazy dog. A quick brown dog jumps over the lazy fox sleeps while the lazy dog. A quick brown fox\n",
            "\n",
            "Order 3:\n",
            "fox jumps over the lazy fox. The lazy fox sleeps while the quick brown dog watches.\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Experiment with different orders\n",
        "print(\"\\nOrder 1:\")\n",
        "chain1 = build_markov_chain(sample_text, order=1)\n",
        "print(generate_text(chain1, order=1))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "chain3 = build_markov_chain(sample_text, order=3)\n",
        "print(generate_text(chain3, order=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb4tHn0_d4E-"
      },
      "source": [
        "2. Use Your Own Text:\n",
        "   Below, try using a different text source. You could use:\n",
        "   - Song lyrics\n",
        "   - Book excerpts\n",
        "   - Movie quotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60lNnPPRd4E-",
        "outputId": "79a888c7-fecc-4937-f2c5-ce670d342df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you! I am accompanied by someone who can sing along in the jury, I'm curious, bear with pride I am not throwing away my right hand man Treasury or State?\n"
          ]
        }
      ],
      "source": [
        "# Task 2: Add your own text here\n",
        "your_text = \"\"\"\n",
        "After the war I went back to New York\n",
        "A-After the war I went back to New York\n",
        "I finished up my studies and I practiced law\n",
        "I practiced law, Burr worked next door\n",
        "Even though we started at the very same time\n",
        "Alexander Hamilton began to climb\n",
        "How to account for his rise to the top?\n",
        "Man, the man is\n",
        "Non-stop!\n",
        "Gentlemen of the jury, I'm curious, bear with me\n",
        "Are you aware that we're making history?\n",
        "This is the first murder trial of our brand-new nation\n",
        "The liberty behind deliberation\n",
        "Non-stop!\n",
        "I am meant to prove beyond a shadow of a doubt\n",
        "With my assistant counsel—\n",
        "Co-counsel. Hamilton, sit down\n",
        "Our client Levi Weeks is innocent, call your first witness\n",
        "That's all you had to say\n",
        "Okay, one more thing—\n",
        "Why do you assume you're the smartest in the room?\n",
        "Why do you assume you're the smartest in the room?\n",
        "Why do you assume you're the smartest in the room?\n",
        "Soon that attitude may be your doom\n",
        "Aww!\n",
        "Why do you write like you're running out of time?\n",
        "Write day and night like you're running out of time\n",
        "Every day you fight like you're running out of time\n",
        "Keep on fighting, in the meantime\n",
        "Non-stop!\n",
        "Corruption's such an old song that we can sing along in harmony\n",
        "And nowhere is it stronger than in Albany\n",
        "This colony's economy's increasingly stalling\n",
        "And honestly, that's why (He's just)\n",
        "Public service seems to be (non-stop!) calling me\n",
        "I practiced the law, practic'ly perfected it\n",
        "I've seen injustice in the world and I've corrected it\n",
        "Now for a strong central democracy\n",
        "If not, then I'll be Socrates\n",
        "Throwing verbal rocks at these mediocrities (Awww!)\n",
        "Hamilton at the Constitutional Convention\n",
        "I was chosen for the Constitutional Convention!\n",
        "There as a New York junior delegate\n",
        "Now what I'm gonna say may sound indelicate... (Awww!)\n",
        "Goes and proposes his own form of government\n",
        "What?\n",
        "His own plan for a new form of government\n",
        "What?\n",
        "Talks for six hours, the convention is listless\n",
        "Bright young man!\n",
        "Yo, who the eff is this?\n",
        "Why do you always say what you believe?\n",
        "Why do you always say what you believe?\n",
        "Every proclamation guarantees\n",
        "Free ammunition for your enemies (Awww!)\n",
        "Why do you write like it's going out of style (goin out of style, hey)\n",
        "Write day and night like it's going out of style (goin out of style, hey)\n",
        "Every day you fight like it's going out of style\n",
        "Do you what you do\n",
        "Alexander?\n",
        "Aaron Burr, sir\n",
        "Well, it's the middle of the night\n",
        "Can we confer, sir?\n",
        "Is this a legal matter?\n",
        "Yes, and it's important to me\n",
        "What do you need?\n",
        "Burr, you're a better lawyer than me\n",
        "Okay?\n",
        "I know I talk too much, I'm abrasive\n",
        "You're incredible in court, you're succinct, persuasive\n",
        "My client needs a strong defence, you're the solution\n",
        "Who's your client?\n",
        "The new U.S. Constitution?\n",
        "No\n",
        "Hear me out—\n",
        "No way!\n",
        "A series of essays anonymously published\n",
        "Defending the document to the public\n",
        "No one'll read it\n",
        "I disagree!\n",
        "And if it fails?\n",
        "Burr, that's why we need it\n",
        "The constitution's a mess!\n",
        "So it needs amendments\n",
        "It's full of contradictions!\n",
        "So is independence\n",
        "We have to start somewhere\n",
        "No, no, no, no, no, no way\n",
        "You're making a mistake\n",
        "Good night!\n",
        "Hey! What are you waiting for?\n",
        "What do you stall for?\n",
        "What?\n",
        "We won the war, what was it all for?\n",
        "Do you support this constitution?\n",
        "Of course\n",
        "Then defend it!\n",
        "And what if you're backing the wrong horse?\n",
        "Burr, we studied and we fought and we killed\n",
        "For the notion of a nation we now get to build\n",
        "For once in your life take a stand with pride\n",
        "I don't understand how you stand to the side\n",
        "I don't keep all my plans close to my chest\n",
        "Wait for it, wait for it, wait\n",
        "I won't wait here and see which\n",
        "Way the wind will blow\n",
        "I'm taking my time watching the afterbirth of a nation\n",
        "Watching the tension grow\n",
        "I am sailing off to London\n",
        "I am accompanied by someone who always pays\n",
        "I have found a wealthy husband\n",
        "Who will keep me in comfort for all my days\n",
        "He is not a lot of fun but\n",
        "There's no one who can match you for turn of phrase\n",
        "My Alexander—\n",
        "Angelica\n",
        "Don't forget to write\n",
        "Look at where you are\n",
        "Look at where you started\n",
        "The fact that you're alive is a miracle\n",
        "Just stay alive, that would be enough\n",
        "And if your wife could share a fraction of your time\n",
        "If I could grant you peace of mind\n",
        "Would that be enough?\n",
        "Alexander joins forces with James Madison and John Jay to write a series of essays Defending the new United States Constitution, entitled The Federalist Papers\n",
        "The plan was to write a total of twenty-five essays\n",
        "The work divided evenly among the three men\n",
        "In the end, they wrote eighty-five essays in the span of six months\n",
        "John Jay got sick after writing five\n",
        "James Madison wrote twenty-nine\n",
        "Hamilton wrote the other FIFTY-ONE!\n",
        "How do you write like you're\n",
        "Running out time\n",
        "Write day and night like you're\n",
        "Running out time\n",
        "Every day you fight like you're\n",
        "Running out time\n",
        "Like you're\n",
        "Running out time\n",
        "Are you running out time?\n",
        "How do you write like tomorrow won't arrive?\n",
        "How do you write like you need it to survive?\n",
        "How do you write every second you're alive\n",
        "Every second you're alive\n",
        "Every second you're alive\n",
        "They're asking me to lead\n",
        "I'm doing the best I can\n",
        "To get the people that I need\n",
        "I'm asking you to be my right hand man\n",
        "Treasury or State?\n",
        "I know it's a lot to ask—\n",
        "Treasury or State?\n",
        "To leave behind the world you know—\n",
        "Sir, do you want me to run the Treasury or State Department?\n",
        "Treasury\n",
        "Let's go\n",
        "Alexander!\n",
        "I have to leave\n",
        "Alexander!\n",
        "Look around, look around at how lucky we are to be alive right now\n",
        "Helpless\n",
        "They are asking me to lead\n",
        "Look around, isn't this enough?\n",
        "He will never be satisfied\n",
        "Would it be enough?\n",
        "He will never be satisfied\n",
        "Satisfied, satisfied, satisfied\n",
        "History has it's eyes on you\n",
        "Why do you assume you're the smartest in the room?\n",
        "Why do you assume you're the smartest in the room?\n",
        "Look around, look around\n",
        "Non-stop!\n",
        "He will never be satisfied, satisfied, satisfied\n",
        "Why do you assume you're the smartest in the room?\n",
        "Soon that attitude may be your doom\n",
        "Isn't this enough? Would it be enough?\n",
        "History has it's eyes on you\n",
        "Why do you write like you're running out of time?\n",
        "Non-stop!\n",
        "Why do you write like—\n",
        "History has it's eyes on you!\n",
        "I am not throwing away my shot!\n",
        "Just you wait\n",
        "I am not throwing away my shot!\n",
        "Just you wait\n",
        "I am Alexander Hamilton\n",
        "Hamilton\n",
        "Just you wait\n",
        "I am not throwing away my shot!\n",
        "\"\"\"\n",
        "chain4 = build_markov_chain(your_text, order=1)\n",
        "print(generate_text(chain4, order=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E36XQS7Ad4E-"
      },
      "source": [
        "3. Advanced Implementation:\n",
        "   Add temperature-based sampling to control randomness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RIIGAAgd4E-",
        "outputId": "ff5889cc-f452-4bee-ec67-2ee94c5e6d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Low temperature (more predictable):\n",
            "lazy dog. A quick brown dog jumps over the lazy dog. A quick brown dog jumps over the lazy fox. The lazy fox sleeps while the quick brown dog jumps\n",
            "\n",
            "High temperature (more random):\n",
            "dog jumps over the lazy fox. The lazy fox sleeps while the quick brown fox jumps over the lazy dog. A quick brown dog jumps over the lazy dog. A\n"
          ]
        }
      ],
      "source": [
        "def generate_text_with_temperature(chain, temperature=1.0, order=2, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate text with temperature-based sampling.\n",
        "    Lower temperature = more conservative/predictable\n",
        "    Higher temperature = more random/creative\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain\n",
        "        temperature (float): Controls randomness (0.1 to 2.0 recommended)\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "    \"\"\"\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            # Count frequencies of next words\n",
        "            next_words = chain[state]\n",
        "            word_counts = defaultdict(int)\n",
        "            for word in next_words:\n",
        "                word_counts[word] += 1\n",
        "\n",
        "            # Apply temperature\n",
        "            weights = [count ** (1.0 / temperature) for count in word_counts.values()]\n",
        "            total = sum(weights)\n",
        "            weights = [w/total for w in weights]\n",
        "\n",
        "            # Choose next word based on weighted probabilities\n",
        "            next_word = random.choices(list(word_counts.keys()), weights=weights)[0]\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Try different temperatures\n",
        "print(\"\\nLow temperature (more predictable):\")\n",
        "print(generate_text_with_temperature(chain, temperature=0.3))\n",
        "\n",
        "print(\"\\nHigh temperature (more random):\")\n",
        "print(generate_text_with_temperature(chain, temperature=2.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yJ3l5wld4E_"
      },
      "source": [
        "## Challenge Tasks:\n",
        "\n",
        "1. Implement a function to analyze the Markov chain:\n",
        "   - Count the number of unique states\n",
        "   - Find the most common transitions\n",
        "   - Calculate the average number of possible next words for each state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMwbSj_Bd4E_",
        "outputId": "1ceea2e3-4d22-4796-d627-3374b576d33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chain Analysis:\n",
            "Number of unique states: 20\n",
            "Average transitions per state: 1.30\n",
            "\n",
            "Most common transitions:\n",
            "The quick -> brown (count: 1)\n",
            "quick brown -> dog (count: 2)\n",
            "brown fox -> jumps (count: 1)\n",
            "fox jumps -> over (count: 1)\n",
            "jumps over -> the (count: 2)\n"
          ]
        }
      ],
      "source": [
        "def analyze_chain(chain):\n",
        "    \"\"\"\n",
        "    Analyze properties of the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain to analyze\n",
        "    \"\"\"\n",
        "    num_states = len(chain)\n",
        "    total_transitions = sum(len(next_words) for next_words in chain.values())\n",
        "    avg_transitions = total_transitions / num_states if num_states > 0 else 0\n",
        "\n",
        "    # Find most common next word for each state\n",
        "    most_common = {}\n",
        "    for state, next_words in chain.items():\n",
        "        word_counts = defaultdict(int)\n",
        "        for word in next_words:\n",
        "            word_counts[word] += 1\n",
        "        most_common[state] = max(word_counts.items(), key=lambda x: x[1])\n",
        "\n",
        "    print(f\"Number of unique states: {num_states}\")\n",
        "    print(f\"Average transitions per state: {avg_transitions:.2f}\")\n",
        "    print(\"\\nMost common transitions:\")\n",
        "    for state, (word, count) in list(most_common.items())[:5]:  # Show top 5\n",
        "        print(f\"{' '.join(state)} -> {word} (count: {count})\")\n",
        "\n",
        "# Analyze our chain\n",
        "print(\"\\nChain Analysis:\")\n",
        "analyze_chain(chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPDtf8w0d4E_"
      },
      "source": [
        "## Further Exploration:\n",
        "\n",
        "Other ideas to try:\n",
        "1. Modify the code to preserve punctuation\n",
        "2. Add start-of-sentence and end-of-sentence tokens\n",
        "3. Implement bi-directional generation\n",
        "4. Create a chain that works with characters instead of words\n",
        "5. Add input validation and error handling"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iat460",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}